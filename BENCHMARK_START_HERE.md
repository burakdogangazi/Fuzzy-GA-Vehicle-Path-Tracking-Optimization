# BENCHMARK_SUBPROCESS - Complete Implementation


**DELIVERED:**

### 1. Main Script
ğŸ“„ **`src/benchmark_subprocess.py`** (640 lines)
- Direct API approach (similar philosophy to your subprocess method)
- 3 GA Strategies Ã— 2 Paths Ã— 3 Runs = **18 total trainings**
- All metrics collected and organized
- 4 comprehensive CSV exports

### 2. Documentation (4 files)
ğŸ“– **`BENCHMARK_SUBPROCESS_README.md`** - Complete technical guide  
ğŸ“– **`BENCHMARK_SUBPROCESS_TURKCE.md`** - Turkish user guide  
ğŸ“– **`BENCHMARK_QUICK_REFERENCE.md`** - Quick reference card  
ğŸ“– **`BENCHMARK_WORKFLOW.md`** - Architecture & flowcharts  

---

## ğŸ¯ HOW TO RUN

```bash
cd c:\Users\burakdogan\Desktop\BulanÄ±kMantÄ±kProje\Proje\BMProje
python src\benchmark_subprocess.py
```

**Result:** 4 CSV files in `src/results/benchmark/`

---

## ğŸ“Š THE 4 CSV FILES

### CSV 1: `benchmark_detailed_runs_*.csv`
**What:** Every single run's full metrics  
**Size:** 18 rows Ã— 20 columns  
**Use:** Individual run inspection, outlier detection  
**Example:**
```
strategy,path,run_id,population_size,fitness_value,crashed,success_rate
aggressive_exploration,convex,1,500,0.2534,0,1.0
aggressive_exploration,convex,2,500,0.2512,0,1.0
...
```

### CSV 2: `benchmark_strategy_comparison_*.csv`
**What:** Strategies compared across paths  
**Structure:** Each metric has 3 rows (one per strategy)  
**Use:** "Which strategy performs best overall?"  
**Example:**
```
metric,strategy,convex_avg,sin_avg,convex_better,win_margin
Fitness (lower is better),aggressive_exploration,0.2534,0.3123,Yes,18.83%
Fitness (lower is better),balanced_strategy,0.1845,0.2450,Yes,24.78%
Fitness (lower is better),conservative_exploitation,0.1567,0.1923,Yes,18.52%
```

### CSV 3: `benchmark_path_comparison_*.csv`
**What:** Paths compared across strategies  
**Structure:** Each metric has 2 rows (one per path)  
**Use:** "Which path is harder? Which strategy wins on each?"  
**Example:**
```
metric,path,aggressive_avg,balanced_avg,conservative_avg,best_strategy
Fitness (lower is better),convex,0.2534,0.1845,0.1567,conservative_exploitation
Fitness (lower is better),sin,0.3123,0.2450,0.1923,conservative_exploitation
Success Rate (%),convex,100.0,100.0,100.0,balanced_strategy
```

### CSV 4: `benchmark_summary_statistics_*.csv`
**What:** Summary statistics for each strategy-path combo  
**Size:** 6 rows (3 strategies Ã— 2 paths) Ã— 11 columns  
**Use:** Quick overview, best combo identification  
**Example:**
```
strategy,path,num_runs,avg_fitness,std_fitness,crash_rate_pct,success_rate_pct
aggressive_exploration,convex,3,0.2534,0.0089,0.0,100.0
aggressive_exploration,sin,3,0.3123,0.0245,33.3,66.7
balanced_strategy,convex,3,0.1845,0.0056,0.0,100.0
balanced_strategy,sin,3,0.2450,0.0134,0.0,100.0
conservative_exploitation,convex,3,0.1567,0.0089,0.0,100.0
conservative_exploitation,sin,3,0.1923,0.0145,0.0,100.0
```

---

## ğŸ² THE 3 STRATEGIES

| Strategy | Population | Generations | Mutation | Character | Time |
|----------|-----------|-------------|----------|-----------|------|
| **Aggressive** | 500 | 15 | 0.25 | High exploration, can crash | ~30 min |
| **Balanced** | 1000 | 20 | 0.10 | Steady, reliable | ~45 min |
| **Conservative** | 1500 | 30 | 0.05 | Best quality, slow | ~60 min |

---

## â±ï¸ EXECUTION TIMELINE

```
Total: ~3-4 hours (depending on system)

Aggressive   (6 runs: 3 convex + 3 sin) .... 1 hour
Balanced     (6 runs: 3 convex + 3 sin) .... 1.5 hours
Conservative (6 runs: 3 convex + 3 sin) .... 2 hours
Export & Summary ........................... 5 minutes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: ~4.5 hours (can reduce by reducing runs/params)
```

---

## ğŸ“ˆ KEY METRICS EXPLAINED

| Metric | Meaning | Good Value |
|--------|---------|-----------|
| **fitness** | Path following quality (from GA) | 0.1-0.3 |
| **distance** | Total pixels traveled | Higher is better |
| **crashed** | Vehicle hit boundary | 0 (no crash) |
| **success_rate** | % of successful runs | 100% |
| **crash_rate** | % of runs that crashed | 0% |
| **efficiency** | Distance per fitness unit | Higher is better |
| **left_right_balance** | Sensor symmetry | Lower is better |
| **steering_stability** | Steering smoothness | Lower is better |

---

## ğŸ” HOW TO ANALYZE THE 4 CSVs

### Question 1: "What's the best overall strategy?"
â†’ Open `benchmark_summary_statistics_*.csv`  
â†’ Find row with **lowest avg_fitness**  
â†’ That strategy+path combination is best

### Question 2: "Is Convex easier than Sin?"
â†’ Open `benchmark_strategy_comparison_*.csv`  
â†’ Look at **Fitness (lower is better)** rows  
â†’ Check: is `convex_avg < sin_avg` for all strategies?  
â†’ Yes = Convex is easier

### Question 3: "Which strategy wins on each path?"
â†’ Open `benchmark_path_comparison_*.csv`  
â†’ Check `best_strategy` column  
â†’ Usually: Conservative wins (best fitness)  
â†’ Usually: Balanced most reliable (no crashes)

### Question 4: "Detailed look at specific run?"
â†’ Open `benchmark_detailed_runs_*.csv`  
â†’ Filter by strategy + path  
â†’ Check individual run_id rows  
â†’ Find anomalies/outliers

---

## ğŸ’¡ TYPICAL FINDINGS

What you'll likely see:

âœ“ **Conservative > Balanced > Aggressive** (fitness quality)  
âœ“ **Convex < Sin** (path difficulty) by ~15-25%  
âœ“ **Aggressive on Sin:** Crashes 20-50% of time  
âœ“ **Balanced on both:** Never crashes (reliable)  
âœ“ **Conservative:** Best fitness but 2-3x slower training  
âœ“ **Efficiency:** Sometimes contradicts fitness  

---

## ğŸ› ï¸ CUSTOMIZATION

You can modify parameters in `src/benchmark_subprocess.py`:

```python
GA_STRATEGIES = {
    'aggressive_exploration': {
        'population_size': 500,         # <- Change this
        'max_iterations': 15,           # <- Or this
        'runs': 3,                      # <- Or this (1 = faster)
        'mutation_rate': 0.25,          # <- Or this
        ...
    }
}
```

**To run faster:** Set `runs: 1` (instead of 3)  
**To run much faster:** Comment out conservative strategy  
**To be thorough:** Set `runs: 5`

---

## ğŸ“ FILES CREATED

### Code
- âœ… `src/benchmark_subprocess.py` - Main benchmark script

### Documentation
- âœ… `BENCHMARK_SUBPROCESS_README.md` - English technical guide
- âœ… `BENCHMARK_SUBPROCESS_TURKCE.md` - Turkish user guide
- âœ… `BENCHMARK_QUICK_REFERENCE.md` - Quick reference
- âœ… `BENCHMARK_WORKFLOW.md` - Architecture diagrams
- âœ… `BENCHMARK_SETUP_SUMMARY.md` - Setup summary (this is that)

### Generated (on first run)
- ğŸ“„ `src/results/benchmark/benchmark_detailed_runs_TIMESTAMP.csv`
- ğŸ“„ `src/results/benchmark/benchmark_strategy_comparison_TIMESTAMP.csv`
- ğŸ“„ `src/results/benchmark/benchmark_path_comparison_TIMESTAMP.csv`
- ğŸ“„ `src/results/benchmark/benchmark_summary_statistics_TIMESTAMP.csv`

---

## âœ… CHECKLIST BEFORE RUNNING

- [ ] `src/benchmark_subprocess.py` exists
- [ ] `genetic_algorithm.py` imports work
- [ ] `src/results/` directory writable
- [ ] Python environment configured
- [ ] System has 3-4 hours available
- [ ] No critical processes running (for speed)

---

## ğŸš€ START HERE

```bash
# Navigate to project
cd c:\Users\burakdogan\Desktop\BulanÄ±kMantÄ±kProje\Proje\BMProje

# Run benchmark
python src\benchmark_subprocess.py

# Check results (after completion)
# Open: src/results/benchmark/benchmark_summary_statistics_*.csv in Excel
```

---

## ğŸ“ TROUBLESHOOTING

| Issue | Solution |
|-------|----------|
| **ImportError** | Check genetic_algorithm.py exists |
| **Permission denied** | Check src/results/benchmark/ writable |
| **Timeout** | System too slow, reduce params |
| **Empty CSV** | Check Python process finished |
| **All crashes** | Check path loading & vehicle physics |

---

## ğŸ“š DOCUMENTATION FILES

Read in this order based on your need:

1. **Just run it?** â†’ `BENCHMARK_QUICK_REFERENCE.md`
2. **Understand it?** â†’ `BENCHMARK_SUBPROCESS_TURKCE.md` (Turkish)
3. **Deep dive?** â†’ `BENCHMARK_SUBPROCESS_README.md` (English)
4. **Architecture?** â†’ `BENCHMARK_WORKFLOW.md`
5. **Setup help?** â†’ `BENCHMARK_SETUP_SUMMARY.md` (this file)

---

## âœ¨ KEY FEATURES

âœ“ **4 CSV Reports** - Different perspectives on same data  
âœ“ **18 Runs** - 3 strategies Ã— 2 paths Ã— 3 repetitions  
âœ“ **Complete Metrics** - 20+ metrics per run  
âœ“ **Non-invasive** - Doesn't modify source code  
âœ“ **Reproducible** - Same params = same results  
âœ“ **Academic Quality** - Proper methodology  
âœ“ **Well Documented** - 5 guides + code comments  

---

## ğŸ“ ACADEMIC VALUE

This benchmark setup answers:

1. **How do GA parameters affect path following?**
   - Aggressive vs Balanced vs Conservative
   - Can directly compare convergence strategies

2. **Which navigation path is harder?**
   - Convex vs Sin
   - Quantified difficulty metric

3. **Strategy-path interaction?**
   - Does best strategy change per path?
   - Robustness analysis

4. **Consistency vs Quality?**
   - Standard deviation of fitness
   - Success rate (reliability)

5. **Scalability testing?**
   - Population size impact
   - Generation count impact

---

## ğŸ¯ NEXT STEPS

1. **Run benchmark** (3-4 hours)
2. **Review 4 CSVs** (30 min)
3. **Create plots** from CSV data (optional)
4. **Write conclusions** based on data
5. **Compare with your bench_runner results** (if running that)

---

## ğŸ’¾ FILE SIZES

Expected CSV sizes:
- `benchmark_detailed_runs_*.csv` - ~50 KB
- `benchmark_strategy_comparison_*.csv` - ~15 KB
- `benchmark_path_comparison_*.csv` - ~10 KB
- `benchmark_summary_statistics_*.csv` - ~2 KB

**Total:** ~80 KB (all 4 files)

---

Ready? Let's go! ğŸš€

```bash
python src\benchmark_subprocess.py
```
